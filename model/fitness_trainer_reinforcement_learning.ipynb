{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-dztnsUFKMB",
        "outputId": "4acb5d61-6024-47fb-8bb8-54205ecb3366"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zD8pk4LYFIRh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras keras-rl2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBoGjZgeFKnc",
        "outputId": "a1de3287-d229-4211-f6c0-30d79c65af08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl.metadata (304 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-rl2) (2.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.44.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->keras-rl2) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->keras-rl2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow->keras-rl2) (2.1.5)\n",
            "Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d niharika41298/gym-exercise-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x20NEK84F9pu",
        "outputId": "4c128cc1-7bf3-48b0-cc29-f175e1dc3860"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/niharika41298/gym-exercise-data\n",
            "License(s): CC0-1.0\n",
            "Downloading gym-exercise-data.zip to /content\n",
            "  0% 0.00/120k [00:00<?, ?B/s]\n",
            "100% 120k/120k [00:00<00:00, 55.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/gym-exercise-data.zip', 'r')\n",
        "zip_ref.extractall('/content/alldata')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "DHPbilUf-8Ms"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gym import Env\n",
        "from gym import spaces\n",
        "from gym.spaces import Discrete, Box\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "c3RmarBtGyn3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/alldata/megaGymDataset.csv')\n",
        "new_df = data.drop(columns=[\"Rating\",\"RatingDesc\"])\n"
      ],
      "metadata": {
        "id": "q1Xwl9KgqBRo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.rename(columns={'Unnamed: 0': 'S.no', 'Unnamed: 1': 'NewName2'}, inplace=True)"
      ],
      "metadata": {
        "id": "lx-1KoNSO8mQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "CS5hSERPQ-gI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv('new_data.csv')"
      ],
      "metadata": {
        "id": "3ZUN9qNIQcWc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym import Env, spaces\n",
        "\n",
        "class fitness_model:\n",
        "    def __init__(self, difficulty=None, purpose=None):\n",
        "        self.action_space = spaces.Discrete(2918)\n",
        "        self.observation_space = spaces.MultiDiscrete([2918, 2918, 2918, 2918, 2918])\n",
        "        self.state = np.random.randint(0, 2918, size=5)\n",
        "        self.reward = 0\n",
        "        self.difficulty = difficulty\n",
        "        self.purpose = purpose\n",
        "        self.new_df = pd.read_csv(\"new_data.csv\")\n",
        "        self.step_count = 0\n",
        "\n",
        "    def selector(self):\n",
        "        arr = self.state.tolist()\n",
        "\n",
        "        for k in range(4):\n",
        "            temp_row = self.new_df.iloc[self.state[k]]\n",
        "            level_match = temp_row[\"Level\"] == self.difficulty\n",
        "            type_match = temp_row[\"Type\"] == self.purpose\n",
        "\n",
        "            if not level_match or not type_match:\n",
        "                break\n",
        "            elif len(temp_row[\"BodyPart\"]) == len(np.unique(temp_row[\"BodyPart\"])):\n",
        "                break\n",
        "\n",
        "        return k\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        self.reward = 0\n",
        "\n",
        "        exercise_to_replace = self.selector()\n",
        "        new_exercise = action\n",
        "\n",
        "        if new_exercise not in self.state:\n",
        "            self.state[exercise_to_replace] = new_exercise\n",
        "\n",
        "\n",
        "\n",
        "        if len(self.state) == len(np.unique(self.state)):\n",
        "            diff = 2\n",
        "        else:\n",
        "            diff = -1\n",
        "\n",
        "        array = self.state.tolist()\n",
        "        temp = self.new_df.iloc[array]\n",
        "\n",
        "\n",
        "        if temp.shape[0] > 0:\n",
        "            if len(temp[\"BodyPart\"]) == len(np.unique(temp[\"BodyPart\"])):\n",
        "                diverse = 1\n",
        "            else:\n",
        "                diverse = -1\n",
        "        else:\n",
        "            diverse = -1\n",
        "\n",
        "\n",
        "        pref_level = 0\n",
        "        for k in self.state:\n",
        "            if self.new_df.loc[k, \"Level\"] == self.difficulty and self.difficulty is not None:\n",
        "                pref_level += 1\n",
        "                break\n",
        "\n",
        "        pref_purpose = 0\n",
        "        for k in self.state:\n",
        "            if self.new_df.loc[k, \"Type\"] != self.purpose and self.purpose is not None:\n",
        "                pref_purpose += 1\n",
        "\n",
        "\n",
        "        self.reward = (3 * diverse) +  pref_purpose + pref_level + diff\n",
        "\n",
        "        if self.reward >= 10  :\n",
        "            done = True\n",
        "            self.step_count = 0\n",
        "        else:\n",
        "            done = False\n",
        "\n",
        "        info = {}\n",
        "        self.step_count+=1\n",
        "        return self.state, self.reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "        print(self.state)\n",
        "\n",
        "    def filter_exercises(self):\n",
        "\n",
        "            if self.difficulty and self.purpose:\n",
        "                return self.new_df[(self.new_df[\"Level\"] == self.difficulty) & (self.new_df[\"Type\"] != self.purpose)]\n",
        "            return self.new_df\n",
        "\n",
        "    def reset(self):\n",
        "\n",
        "        self.state = np.random.randint(0, 2918, size=5)\n",
        "\n",
        "        return self.state\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GIsuWgTNt0yD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "# Environment setup\n",
        "env = fitness_model(\"Beginner\",\"Strength\")\n",
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "\n",
        "# Hyperparameters\n",
        "gamma = 0.99  # Discount factor\n",
        "lr_actor = 0.001  # Actor learning rate\n",
        "lr_critic = 0.001  # Critic learning rate\n",
        "clip_ratio = 0.2  # PPO clip ratio\n",
        "epochs = 10  # Number of optimization epochs\n",
        "batch_size = 64  # Batch size for optimization\n",
        "\n",
        "# Actor and Critic networks\n",
        "class ActorCritic(tf.keras.Model):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.policy_logits = tf.keras.layers.Dense(action_size)\n",
        "        self.dense2 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.value = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, state):\n",
        "        x = self.dense1(state)\n",
        "        logits = self.policy_logits(x)\n",
        "        value = self.value(x)\n",
        "        return logits, value\n",
        "\n",
        "# PPO algorithm\n",
        "def ppo_loss(old_logits, old_values, advantages, states, actions, returns):\n",
        "    def compute_loss(logits, values, actions, returns):\n",
        "        actions_onehot = tf.one_hot(actions, action_size, dtype=tf.float32)\n",
        "        policy = tf.nn.softmax(logits)\n",
        "        action_probs = tf.reduce_sum(actions_onehot * policy, axis=1)\n",
        "        old_policy = tf.nn.softmax(old_logits)\n",
        "        old_action_probs = tf.reduce_sum(actions_onehot * old_policy, axis=1)\n",
        "\n",
        "        # Policy loss\n",
        "        ratio = tf.exp(tf.math.log(action_probs + 1e-10) - tf.math.log(old_action_probs + 1e-10))\n",
        "        clipped_ratio = tf.clip_by_value(ratio, 1 - clip_ratio, 1 + clip_ratio)\n",
        "        policy_loss = -tf.reduce_mean(tf.minimum(ratio * advantages, clipped_ratio * advantages))\n",
        "\n",
        "        # Value loss\n",
        "        value_loss = tf.reduce_mean(tf.square(values - returns))\n",
        "\n",
        "        # Entropy bonus (optional)\n",
        "        entropy_bonus = tf.reduce_mean(policy * tf.math.log(policy + 1e-10))\n",
        "\n",
        "        total_loss = policy_loss + 0.5 * value_loss - 0.01 * entropy_bonus  # Entropy regularization\n",
        "        return total_loss\n",
        "\n",
        "    def get_advantages(returns, values):\n",
        "        advantages = returns - values\n",
        "        return (advantages - tf.reduce_mean(advantages)) / (tf.math.reduce_std(advantages) + 1e-8)\n",
        "\n",
        "    def train_step(states, actions, returns, old_logits, old_values):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits, values = model(states)\n",
        "            loss = compute_loss(logits, values, actions, returns)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    advantages = get_advantages(returns, old_values)\n",
        "    for _ in range(epochs):\n",
        "        loss = train_step(states, actions, returns, old_logits, old_values)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Initialize actor-critic model and optimizer\n",
        "model = ActorCritic(state_size, action_size)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_actor)\n",
        "\n",
        "# Main training loop\n",
        "max_episodes = 1000\n",
        "max_steps_per_episode = 200\n",
        "\n",
        "for episode in range(max_episodes):\n",
        "    states, actions, rewards, values, returns = [], [], [], [], []\n",
        "    state = env.reset()\n",
        "    for step in range(max_steps_per_episode):\n",
        "        state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
        "        logits, value = model(state)\n",
        "\n",
        "        # Sample action from the policy distribution\n",
        "        action = tf.random.categorical(logits, 1)[0, 0].numpy()\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        states.append(state)\n",
        "        actions.append(action)\n",
        "        rewards.append(reward)\n",
        "        values.append(value)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "            returns_batch = []\n",
        "            discounted_sum = 0\n",
        "            for r in rewards[::-1]:\n",
        "                discounted_sum = r + gamma * discounted_sum\n",
        "                returns_batch.append(discounted_sum)\n",
        "            returns_batch.reverse()\n",
        "\n",
        "            states = tf.concat(states, axis=0)\n",
        "            actions = np.array(actions, dtype=np.int32)\n",
        "            values = tf.concat(values, axis=0)\n",
        "            returns_batch = tf.convert_to_tensor(returns_batch)\n",
        "            old_logits, _ = model(states)\n",
        "\n",
        "            loss = ppo_loss(old_logits, values, returns_batch - np.array(values), states, actions, returns_batch)\n",
        "            print(f\"Episode: {episode + 1}, Loss: {loss.numpy()},State: {next_state}\")\n",
        "\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m63SHkk8GUGq",
        "outputId": "72a9cf62-d521-4c48-f7c6-b2c90505c05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'actor_critic_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 2, Loss: 240.26754760742188,State: [2344  432 2838  453 2839]\n",
            "Episode: 4, Loss: 2531.9443359375,State: [2745 1230  848 2159 2500]\n",
            "Episode: 6, Loss: 3351.150390625,State: [2745 2124   96 2277 2275]\n",
            "Episode: 8, Loss: 11035.8955078125,State: [ 990 2745 2046 1583 1754]\n",
            "Episode: 10, Loss: 1764.2806396484375,State: [2745  253 1690 2129  550]\n",
            "Episode: 12, Loss: 5919.92822265625,State: [2886 2313 1035 1647  385]\n",
            "Episode: 14, Loss: 7634.45556640625,State: [2886 1747  165 2371 2836]\n",
            "Episode: 16, Loss: 7666.92138671875,State: [2886 2686 2083  560  229]\n",
            "Episode: 18, Loss: 14015.3427734375,State: [2745 1210 2263 1918  542]\n",
            "Episode: 20, Loss: 6141.70703125,State: [2745 2306 1039 2868  206]\n",
            "Episode: 22, Loss: 3569.700927734375,State: [2745  340 2388  895 2506]\n",
            "Episode: 24, Loss: 1384.6776123046875,State: [2745 2002 2263 2316 2032]\n",
            "Episode: 26, Loss: 7290.43603515625,State: [2692 2745 2374 2339  852]\n",
            "Episode: 28, Loss: 21415.109375,State: [2745  836 1177  886 1912]\n",
            "Episode: 30, Loss: 18062.544921875,State: [2745 2056  812 2123  731]\n",
            "Episode: 32, Loss: 10793.0966796875,State: [2745 2012 1413  124 1256]\n",
            "Episode: 34, Loss: 8646.2451171875,State: [2745 1659  633 1350 2295]\n",
            "Episode: 36, Loss: 168.02671813964844,State: [2745  230 2445 2613 2428]\n",
            "Episode: 38, Loss: 6038.46826171875,State: [2745   49 2431  105  805]\n",
            "Episode: 40, Loss: 380.15313720703125,State: [2745 2676 1176 2624 2894]\n",
            "Episode: 42, Loss: 2532.530029296875,State: [2745  418 1857  124  819]\n",
            "Episode: 44, Loss: 18015.693359375,State: [2745 1209  829 1939  978]\n",
            "Episode: 46, Loss: 10213.7275390625,State: [2745 2094  831  973 1316]\n",
            "Episode: 48, Loss: 1739.246337890625,State: [2745 2550 1429 1026 1060]\n",
            "Episode: 50, Loss: 11218.779296875,State: [2745  407 2064 2812  784]\n",
            "Episode: 52, Loss: 7993.6318359375,State: [2745  752 1523 1389 2378]\n",
            "Episode: 54, Loss: 11321.4990234375,State: [2745  936 1851 1751 2909]\n",
            "Episode: 56, Loss: 2041.3427734375,State: [2745 2565 1291 2797 2605]\n",
            "Episode: 58, Loss: 2606.86474609375,State: [2745  710 1877  821 1892]\n",
            "Episode: 60, Loss: 638.8248291015625,State: [ 931 2745 2355  378  923]\n",
            "Episode: 62, Loss: 1099.8463134765625,State: [2745 2286 2366 2614 2531]\n",
            "Episode: 64, Loss: 2976.04443359375,State: [2745 1010 1368 1626 1159]\n",
            "Episode: 66, Loss: 5876.76611328125,State: [2745 1892 2777 1019  684]\n",
            "Episode: 68, Loss: 13278.1494140625,State: [2745  667 2364  706 1379]\n",
            "Episode: 70, Loss: 6024.8857421875,State: [2745 1907   30  894 1672]\n",
            "Episode: 72, Loss: 690.7188110351562,State: [2745 2637 1789 1383 2620]\n",
            "Episode: 74, Loss: 8055.19921875,State: [2745 1439 1761 2285 2842]\n",
            "Episode: 76, Loss: 10460.2080078125,State: [2745 2276  667 1115 1177]\n",
            "Episode: 78, Loss: 12591.75,State: [2745 2015 1750 1679  447]\n",
            "Episode: 80, Loss: 9858.2060546875,State: [ 741 2745   63 1246 2897]\n",
            "Episode: 82, Loss: 663.0067749023438,State: [2745 2299 1608 2520 2489]\n",
            "Episode: 84, Loss: 509.5094909667969,State: [ 194 2745  185  210  596]\n",
            "Episode: 86, Loss: 6512.68212890625,State: [2745  143 1222 1766 2198]\n",
            "Episode: 88, Loss: 2542.238037109375,State: [2745 2688 1753 1770 1162]\n",
            "Episode: 90, Loss: 2081.704833984375,State: [2745 1302 2626 1925  573]\n",
            "Episode: 92, Loss: 1947.424560546875,State: [2745 1987 2913 2334   12]\n",
            "Episode: 94, Loss: 127.77122497558594,State: [2745 2289 1211 2108 1761]\n",
            "Episode: 96, Loss: 6229.75439453125,State: [2745 1564 2857  452 1658]\n",
            "Episode: 98, Loss: 13157.89453125,State: [2745 2120  802 1173 1641]\n",
            "Episode: 100, Loss: 9608.474609375,State: [2745  187 1100 1881 1585]\n",
            "Episode: 102, Loss: 9581.4404296875,State: [2745 1463 1149  683 1244]\n",
            "Episode: 104, Loss: 264.6909484863281,State: [2745 2481  934 2733 1716]\n",
            "Episode: 106, Loss: 10819.400390625,State: [1777 1166 1191 2745 2024]\n",
            "Episode: 108, Loss: 2403.527587890625,State: [2745 1529 2772  201  268]\n",
            "Episode: 110, Loss: 308.87884521484375,State: [2745 1810  618  678  206]\n",
            "Episode: 112, Loss: 876.62353515625,State: [2745  706 2583  463 2543]\n",
            "Episode: 114, Loss: 234.2678985595703,State: [2745 1865 2298 1349 2567]\n",
            "Episode: 116, Loss: 390.6670227050781,State: [2745 1049 2642 2564 1737]\n",
            "Episode: 118, Loss: 8675.634765625,State: [2745  511 1221 1836 2841]\n",
            "Episode: 120, Loss: 190.9117431640625,State: [2745  817  901  898 1638]\n",
            "Episode: 122, Loss: 673.3657836914062,State: [2745   12 2005 2208  112]\n",
            "Episode: 124, Loss: 679.6655883789062,State: [2745 1349 1775  405  361]\n",
            "Episode: 126, Loss: 8164.86083984375,State: [2745 2106  915 1441 1264]\n",
            "Episode: 128, Loss: 8200.736328125,State: [ 158 2745 1691 1875 1491]\n",
            "Episode: 130, Loss: 720.2042236328125,State: [2745 1162 1590  356  544]\n",
            "Episode: 132, Loss: 784.76318359375,State: [2745 2575 2333  129 2271]\n",
            "Episode: 134, Loss: 964.97998046875,State: [ 989 2745 1467  230  250]\n",
            "Episode: 136, Loss: 90.33783721923828,State: [2745 1990  858 1727  779]\n",
            "Episode: 138, Loss: 668.3858032226562,State: [2745 2757 1324  379 1410]\n",
            "Episode: 140, Loss: 397.783203125,State: [2745 1460 1698  770 1708]\n",
            "Episode: 142, Loss: 152.40003967285156,State: [2745 1002  591  157 1553]\n",
            "Episode: 144, Loss: 652.7329711914062,State: [2745 1868 2114 1178 2467]\n",
            "Episode: 146, Loss: 1732.29345703125,State: [2745 2465  381 1328  580]\n",
            "Episode: 148, Loss: 379.1580810546875,State: [2745 1225  942 2504 1840]\n",
            "Episode: 150, Loss: 829.0858764648438,State: [2745 1474 2872 1445 2014]\n",
            "Episode: 152, Loss: 9322.466796875,State: [2745 1458 1729  805 1106]\n",
            "Episode: 154, Loss: 10698.232421875,State: [ 872 2745 1410 1044  222]\n",
            "Episode: 156, Loss: 10490.921875,State: [2745 1569 1961  297 1355]\n",
            "Episode: 158, Loss: 17814.384765625,State: [2745 1049 1194 1384  619]\n",
            "Episode: 160, Loss: 408.3407287597656,State: [2745 2385 1413 2678 2593]\n",
            "Episode: 162, Loss: 3390.424072265625,State: [2745  147  437  508 2541]\n",
            "Episode: 164, Loss: 464.72723388671875,State: [2745 2824 1561 2827  442]\n",
            "Episode: 166, Loss: 1023.560791015625,State: [2745  664  166  141 1076]\n",
            "Episode: 168, Loss: 1206.110595703125,State: [2745  446 2333 2495   49]\n",
            "Episode: 170, Loss: 18429.419921875,State: [2745 2825 1367 2071    3]\n",
            "Episode: 172, Loss: 2791.01123046875,State: [2745 2373 2058 2359 2042]\n",
            "Episode: 174, Loss: 8214.5087890625,State: [ 981 2745  499 1506 1225]\n",
            "Episode: 176, Loss: 173.03854370117188,State: [2745 1073   87  165 1085]\n",
            "Episode: 178, Loss: 192.6313018798828,State: [ 741 2745 2405  101 2551]\n",
            "Episode: 180, Loss: 11.67694091796875,State: [2745 1686  396 2636 1032]\n",
            "Episode: 182, Loss: 17297.544921875,State: [1704 1226 2745  962  233]\n",
            "Episode: 184, Loss: 3932.52392578125,State: [2745  187 1314 2400  631]\n",
            "Episode: 186, Loss: 1989.157958984375,State: [2745 1161 1802  737 1081]\n",
            "Episode: 188, Loss: 1292.6234130859375,State: [2745 2540  932  437 2366]\n",
            "Episode: 190, Loss: 871.3690795898438,State: [2745 1947 1387 1938  818]\n",
            "Episode: 192, Loss: 2151.536376953125,State: [2745  193 1002  218 1398]\n",
            "Episode: 194, Loss: 80.81532287597656,State: [2745   82   79 1761   10]\n",
            "Episode: 196, Loss: 2542.255615234375,State: [2745 2725 1151  635 1897]\n",
            "Episode: 198, Loss: 1546.6998291015625,State: [2745 2043  158 2520 2614]\n",
            "Episode: 200, Loss: 1565.0340576171875,State: [2745 1765 1366 1541 1380]\n",
            "Episode: 202, Loss: 10523.23046875,State: [2745 1289 1664 1512 1582]\n",
            "Episode: 204, Loss: 7879.578125,State: [2745  531 1492  214 1713]\n",
            "Episode: 206, Loss: 12659.84765625,State: [1353 2745 1212  973 2424]\n",
            "Episode: 208, Loss: 180.3014373779297,State: [2745  151 2054 2326 2137]\n",
            "Episode: 210, Loss: 1673.2054443359375,State: [2745 2702 2099 1603 2605]\n",
            "Episode: 212, Loss: 209.90130615234375,State: [2745  504  859 2872  549]\n",
            "Episode: 214, Loss: 948.0025024414062,State: [2745 2638 1933 2113 2126]\n",
            "Episode: 216, Loss: 11448.0869140625,State: [2745 1182 1595 2259   65]\n",
            "Episode: 218, Loss: 2037.3399658203125,State: [2745 2504 1370  756 1176]\n",
            "Episode: 220, Loss: 10527.3427734375,State: [2745 1763 2053 2778  744]\n",
            "Episode: 222, Loss: 854.6589965820312,State: [2745   26 2641  119 2803]\n",
            "Episode: 224, Loss: 1772.3822021484375,State: [1057 2745 2828 2913 1585]\n",
            "Episode: 226, Loss: 5241.884765625,State: [2745 1913 1597 2535  543]\n",
            "Episode: 228, Loss: 1201.4075927734375,State: [2745  285 2057 2606  507]\n",
            "Episode: 230, Loss: 719.5888671875,State: [2745  862 1024  811 2612]\n",
            "Episode: 232, Loss: 2691.427001953125,State: [2745 1388 1356 1174 2102]\n",
            "Episode: 234, Loss: 10955.1787109375,State: [2745 2071 1758  342 1669]\n",
            "Episode: 236, Loss: 3870.248046875,State: [2745  766 2024  122 2634]\n",
            "Episode: 238, Loss: 11809.1083984375,State: [2745 1557 2835 1718 1991]\n",
            "Episode: 240, Loss: 3576.401611328125,State: [2745 1629 2175 1171 2192]\n",
            "Episode: 242, Loss: 5413.73095703125,State: [2745 2636  899  645  492]\n",
            "Episode: 244, Loss: 5990.43603515625,State: [2745 1745 1454 1437 2278]\n",
            "Episode: 246, Loss: 16473.05859375,State: [2745 2416   95 1514  955]\n",
            "Episode: 248, Loss: 8220.267578125,State: [2745 2192 2489 1227 2024]\n",
            "Episode: 250, Loss: 1613.0181884765625,State: [2745  101 1606   61  486]\n",
            "Episode: 252, Loss: 9.209197044372559,State: [2745 1956 2225 2265  531]\n",
            "Episode: 254, Loss: 2155.686279296875,State: [2745 2416 1943  800   24]\n",
            "Episode: 256, Loss: 46.33802032470703,State: [2745 2622  360 2904 1958]\n",
            "Episode: 258, Loss: 2345.501953125,State: [2745 1476 1958 2120  438]\n",
            "Episode: 260, Loss: 8654.7568359375,State: [2745 2798 1214  427  945]\n",
            "Episode: 262, Loss: 11471.84765625,State: [2745 2710  776  263 1183]\n",
            "Episode: 264, Loss: 1090.3546142578125,State: [2745 1041 2868 1924 1836]\n",
            "Episode: 266, Loss: 5876.23974609375,State: [2745 1692  143 2299 2907]\n",
            "Episode: 268, Loss: 11191.603515625,State: [2745 2132 2771 1422  712]\n",
            "Episode: 270, Loss: 5018.18896484375,State: [2745 1143 1139 1331 2451]\n",
            "Episode: 272, Loss: 9453.21484375,State: [2745  154  846 1714 1334]\n",
            "Episode: 274, Loss: 3953.68359375,State: [2745 1661  682  883 1237]\n",
            "Episode: 276, Loss: 13518.6064453125,State: [2745 1164 2079 1460 1192]\n",
            "Episode: 278, Loss: 1279.3243408203125,State: [2745  505 2332  120 1555]\n",
            "Episode: 280, Loss: 84.89447021484375,State: [2745 1365 2369  130 1956]\n",
            "Episode: 282, Loss: 667.9434814453125,State: [2745 2413 2120 2142 2563]\n",
            "Episode: 284, Loss: 8808.466796875,State: [2745  418 1204 1732 2826]\n",
            "Episode: 286, Loss: 14613.4111328125,State: [2745   62  492 2358 1188]\n",
            "Episode: 288, Loss: 34657.79296875,State: [2745 1753   38  719 1460]\n",
            "Episode: 290, Loss: 8525.212890625,State: [2745 2194  639 1297 1881]\n",
            "Episode: 292, Loss: 3813.335205078125,State: [2745 2738  216 1433 1477]\n",
            "Episode: 294, Loss: 1264.3702392578125,State: [2745 1012 2225 1548 1048]\n",
            "Episode: 296, Loss: 362.9591064453125,State: [ 989 2745  472 2694 2524]\n",
            "Episode: 298, Loss: 167.3406219482422,State: [ 876 2745  572 2510 2478]\n",
            "Episode: 300, Loss: 929.4030151367188,State: [2745 1295  557  257  104]\n",
            "Episode: 302, Loss: 408.3622741699219,State: [2745 1115 1953 1804 2474]\n",
            "Episode: 304, Loss: 1388.841064453125,State: [2745 2079 2617 2322 2206]\n",
            "Episode: 306, Loss: 651.9896850585938,State: [2745  114 2660  717   76]\n",
            "Episode: 308, Loss: 18081.53515625,State: [2745  924  168 1978 1533]\n",
            "Episode: 310, Loss: 5807.296875,State: [2745  601 1681 2756 1968]\n",
            "Episode: 312, Loss: 8482.3662109375,State: [2745  709  399 2396 2866]\n",
            "Episode: 314, Loss: 1566.6575927734375,State: [2745 1241   15 1314  301]\n",
            "Episode: 316, Loss: 10037.83984375,State: [2745 2349  835  150 1091]\n",
            "Episode: 318, Loss: 1264.94580078125,State: [2745  550 1616 2491 1088]\n",
            "Episode: 320, Loss: 539.1411743164062,State: [2745 2768  720 2478 1449]\n",
            "Episode: 322, Loss: 10265.7421875,State: [2745 1949  686 1123  502]\n",
            "Episode: 324, Loss: 490.5932922363281,State: [2745   59 1361  236 2296]\n",
            "Episode: 326, Loss: 2568.161376953125,State: [2745 1564  725 1598  770]\n",
            "Episode: 328, Loss: 92.5963363647461,State: [2745 2459 2338 2833 1973]\n",
            "Episode: 330, Loss: 1668.4149169921875,State: [2745  215 1370 2125  323]\n",
            "Episode: 332, Loss: 986.6085815429688,State: [2914 2745 1413 1423 2449]\n",
            "Episode: 334, Loss: 27658.880859375,State: [1344 2745 1634  623 2170]\n",
            "Episode: 336, Loss: 8707.1396484375,State: [2745 1123 1593  733  193]\n",
            "Episode: 338, Loss: 1203.0357666015625,State: [2745 1928 2810 2197 2672]\n",
            "Episode: 340, Loss: 574.5484008789062,State: [2745 2684 2213 1917 1414]\n",
            "Episode: 342, Loss: 3959.239501953125,State: [2745 2583 2168 1126 2829]\n",
            "Episode: 344, Loss: 1045.788330078125,State: [ 874 2745   57  193 1094]\n",
            "Episode: 346, Loss: 14211.8447265625,State: [2745 1995 1649 1601  777]\n",
            "Episode: 348, Loss: 1967.5328369140625,State: [2745  151 1932  322 2047]\n",
            "Episode: 350, Loss: 726.6292724609375,State: [1402 2745 1281 1269 2777]\n",
            "Episode: 352, Loss: 862.6011962890625,State: [2745  430 2529 2755 2344]\n",
            "Episode: 354, Loss: 4470.9111328125,State: [2558 2745  372  809 1798]\n",
            "Episode: 356, Loss: 964.5338134765625,State: [2745 1867  906  803 2599]\n",
            "Episode: 358, Loss: 170.77886962890625,State: [2549 2745 1567 2565  415]\n",
            "Episode: 360, Loss: 1029.433837890625,State: [2745  277 1096 1175  149]\n",
            "Episode: 362, Loss: 657.1849975585938,State: [2745 2164 2340 1665 1962]\n",
            "Episode: 364, Loss: 14675.1376953125,State: [2745 1217 1185  457 2055]\n",
            "Episode: 366, Loss: 15125.3984375,State: [2745 2555 1970  780 1943]\n",
            "Episode: 368, Loss: 5440.5498046875,State: [2745 2780  405 1115 2872]\n",
            "Episode: 370, Loss: 1010.7880249023438,State: [2745  397 2537 2779 2378]\n",
            "Episode: 372, Loss: 1664.5882568359375,State: [2745 2180 1477 2367 1599]\n",
            "Episode: 374, Loss: 3049.509521484375,State: [2745 1180 1939 2051 2710]\n",
            "Episode: 376, Loss: 502.1001892089844,State: [2745 2608  460 2568 1507]\n",
            "Episode: 378, Loss: 9.143731117248535,State: [2745 2390 2440   86 1042]\n",
            "Episode: 380, Loss: 866.396484375,State: [2745 1897  199 1015  412]\n",
            "Episode: 382, Loss: 27458.451171875,State: [2745 1395  460 1048 1959]\n",
            "Episode: 384, Loss: 6005.85498046875,State: [2745 1255  774 1950  252]\n",
            "Episode: 386, Loss: 8195.068359375,State: [1199 2745 1770 1894  440]\n",
            "Episode: 388, Loss: 4714.8232421875,State: [2745 2495 2824 2771 1787]\n",
            "Episode: 390, Loss: 388.0728454589844,State: [2745 1245 1555 1909 1570]\n",
            "Episode: 392, Loss: 319.95184326171875,State: [2745  207 1151 2289 2385]\n",
            "Episode: 394, Loss: 4672.97802734375,State: [2799 2561 2745  991 2155]\n",
            "Episode: 396, Loss: 2956.12353515625,State: [2745 2152 1957 2185 1364]\n",
            "Episode: 398, Loss: 1410.7298583984375,State: [2745  695  496 2500  401]\n",
            "Episode: 400, Loss: 55.11326217651367,State: [2745 2902 1421 2353 2525]\n",
            "Episode: 402, Loss: 13506.4384765625,State: [2745 1308 2837  604  923]\n",
            "Episode: 404, Loss: 659.4432983398438,State: [2745 2554  649 2422 2660]\n",
            "Episode: 406, Loss: 12110.359375,State: [2745 2109  551  749  509]\n",
            "Episode: 408, Loss: 3330.9140625,State: [2745 2288   12 2439  358]\n",
            "Episode: 410, Loss: 257.3067932128906,State: [2630 2084 1755 2290 2032]\n",
            "Episode: 412, Loss: 13008.609375,State: [2630  876 1438 2397 1623]\n",
            "Episode: 414, Loss: 5102.259765625,State: [2630  721 2027 2833  269]\n",
            "Episode: 416, Loss: 15356.955078125,State: [2630 1548  119 1710   90]\n",
            "Episode: 418, Loss: 619.5341796875,State: [2630 1991 1636 1195 2495]\n",
            "Episode: 420, Loss: 1822.428955078125,State: [2630 1830 1618 2897 1602]\n",
            "Episode: 422, Loss: 45.75297164916992,State: [2630 1212 2572 2457 1796]\n",
            "Episode: 424, Loss: 1520.128662109375,State: [2630  571 2279  543 2122]\n",
            "Episode: 426, Loss: 176.4210205078125,State: [2745  443  392 1323 2708]\n",
            "Episode: 428, Loss: 1862.4158935546875,State: [2503 2630 1857 2100  371]\n",
            "Episode: 430, Loss: 20417.5,State: [2630 1909   21 1458  954]\n",
            "Episode: 432, Loss: 9184.40625,State: [2630 1864 2407  746 1888]\n",
            "Episode: 434, Loss: 238.6614990234375,State: [2630  466 2288  303 2581]\n",
            "Episode: 436, Loss: 14583.884765625,State: [2630 1759 2097 1189  939]\n",
            "Episode: 438, Loss: 4705.8408203125,State: [2630 1679 2084  397 2809]\n",
            "Episode: 440, Loss: 25835.79296875,State: [2630 2377 1836 1323  742]\n",
            "Episode: 442, Loss: 637.4715576171875,State: [2630 2588  573  499  698]\n",
            "Episode: 444, Loss: 11366.8427734375,State: [2630 1536 1653   61 2106]\n",
            "Episode: 446, Loss: 11604.87109375,State: [2630 1082 1597 1892  527]\n",
            "Episode: 448, Loss: 5069.509765625,State: [2630 2141 1045 2079 1578]\n",
            "Episode: 450, Loss: 8479.6923828125,State: [2630  764 2077 1537 2815]\n",
            "Episode: 452, Loss: 5774.23779296875,State: [2630 2315 2394 1729 2386]\n",
            "Episode: 454, Loss: 10766.3076171875,State: [2630  672  832   29 1867]\n",
            "Episode: 456, Loss: 171.01922607421875,State: [2630 2574  919  431 2171]\n",
            "Episode: 458, Loss: 767.1116943359375,State: [2630 1514 2611 1216  200]\n",
            "Episode: 460, Loss: 104.66913604736328,State: [2630 2746 1270 1653  902]\n",
            "Episode: 462, Loss: 171.794921875,State: [2630 2542 1723 2097 1455]\n",
            "Episode: 464, Loss: 18780.37890625,State: [ 812 2630 1183 1161 2147]\n",
            "Episode: 466, Loss: 7597.64501953125,State: [2630 2187  197  214 1152]\n",
            "Episode: 468, Loss: 3700.203125,State: [2630 1604 1382 2454  661]\n",
            "Episode: 470, Loss: 138.1501007080078,State: [2630 2543  231 1793 2424]\n",
            "Episode: 472, Loss: 229.31227111816406,State: [2630 2057  654 2387  979]\n",
            "Episode: 474, Loss: 9362.8291015625,State: [2630  883 1975  219 1559]\n",
            "Episode: 476, Loss: 3323.2001953125,State: [ 710 2745 1539 2732 1383]\n",
            "Episode: 478, Loss: 9960.10546875,State: [1932 2630 1504 1657  674]\n",
            "Episode: 480, Loss: 4177.43017578125,State: [2745 2676 2423 2762 2756]\n",
            "Episode: 482, Loss: 41386.796875,State: [2630 1472 1211 1394  401]\n",
            "Episode: 484, Loss: 15340.30078125,State: [2745 1260 1941 1715 1473]\n",
            "Episode: 486, Loss: 310.92987060546875,State: [ 986 2745  450  404  444]\n",
            "Episode: 488, Loss: 16619.26171875,State: [2745  387 2237 1534 1543]\n",
            "Episode: 490, Loss: 2806.1279296875,State: [2745 2671 2157 1480 2507]\n",
            "Episode: 492, Loss: 843.0087280273438,State: [2745 2121 1744 2758 1553]\n",
            "Episode: 494, Loss: 801.0304565429688,State: [2745 2531  247  702  904]\n",
            "Episode: 496, Loss: 21845.24609375,State: [2745  872  782 2406   32]\n",
            "Episode: 498, Loss: 11919.796875,State: [2745  781  403  613   31]\n",
            "Episode: 500, Loss: 13744.697265625,State: [2745  765 1100 1182  332]\n",
            "Episode: 502, Loss: 4164.0830078125,State: [2745  576  785 2553 1070]\n",
            "Episode: 504, Loss: 12335.970703125,State: [2745 1597 2274  578 1703]\n",
            "Episode: 506, Loss: 8569.8603515625,State: [2745  979 2756 1522  615]\n",
            "Episode: 508, Loss: 2212.792724609375,State: [2745  598 2506 1923 1608]\n",
            "Episode: 510, Loss: 41873.23046875,State: [2745 1251  142 2158 1578]\n",
            "Episode: 512, Loss: 16508.712890625,State: [2745 1468 1420  419 2271]\n",
            "Episode: 514, Loss: 847.7581787109375,State: [2745  525 2359 2752 2729]\n",
            "Episode: 516, Loss: 15076.5947265625,State: [2745 1002  141 1431 1678]\n",
            "Episode: 518, Loss: 1812.1219482421875,State: [2745    1 2524 1754    1]\n",
            "Episode: 520, Loss: 1538.4609375,State: [2745 2036  630 2136 2763]\n",
            "Episode: 522, Loss: 313.439208984375,State: [2745 1212 2423 1456 1844]\n",
            "Episode: 524, Loss: 8425.21484375,State: [2745 2774 1146 2202   79]\n",
            "Episode: 526, Loss: 2678.303466796875,State: [2745  680 2765 2661  181]\n",
            "Episode: 528, Loss: 4132.43115234375,State: [2745 1369  270  331 2033]\n",
            "Episode: 530, Loss: 422.0532531738281,State: [2745 2744 2718 1348 2631]\n",
            "Episode: 532, Loss: 1133.70361328125,State: [2745 1525 1364 2685 1479]\n",
            "Episode: 534, Loss: 7601.30859375,State: [2745  677 2680 1920 1581]\n",
            "Episode: 536, Loss: 5327.908203125,State: [2745 2717 1677 1829  455]\n",
            "Episode: 538, Loss: 488.7654113769531,State: [2745 2274  650 2682 2490]\n",
            "Episode: 540, Loss: 2055.544677734375,State: [2745  778 2253 1432 1808]\n",
            "Episode: 542, Loss: 23453.818359375,State: [ 749 2745  306  684 1867]\n",
            "Episode: 544, Loss: 7851.556640625,State: [2504 2745  619 2241 2547]\n",
            "Episode: 546, Loss: 9027.337890625,State: [2745 1774 1882  461 1135]\n",
            "Episode: 548, Loss: 1862.8421630859375,State: [2745  348   94 1289 2151]\n",
            "Episode: 550, Loss: 13757.9072265625,State: [ 812 2745  672 1684 1938]\n",
            "Episode: 552, Loss: 2608.846435546875,State: [2745  913 2458 1405  634]\n",
            "Episode: 554, Loss: 5562.06103515625,State: [2745 2780 2868 1905  284]\n",
            "Episode: 556, Loss: 434.26239013671875,State: [ 880 2745 2275 2665  603]\n",
            "Episode: 558, Loss: 649.8764038085938,State: [2745 1844  101  821 2362]\n",
            "Episode: 560, Loss: 832.0819702148438,State: [1226 2745  405 1798  147]\n",
            "Episode: 562, Loss: 282.95074462890625,State: [2745 2047 1823   81  452]\n",
            "Episode: 564, Loss: 739.9400024414062,State: [2745  603  283 1125 1452]\n",
            "Episode: 566, Loss: 1108.1053466796875,State: [2745  758 1059 2331 2169]\n",
            "Episode: 568, Loss: 205.22760009765625,State: [2745  654 2317 2526 1782]\n",
            "Episode: 570, Loss: 2099.1298828125,State: [2745  338 1461 2547 2408]\n",
            "Episode: 572, Loss: 12711.0498046875,State: [2745 2403 1591  509 1040]\n",
            "Episode: 574, Loss: 1716.539794921875,State: [2745 2297 2548  705 2353]\n",
            "Episode: 576, Loss: 876.0864868164062,State: [2745  862  341   25 2395]\n",
            "Episode: 578, Loss: 27430.6875,State: [2745  871  110 1987 1032]\n",
            "Episode: 580, Loss: 6688.66650390625,State: [2745 2794 1550 1135 1555]\n",
            "Episode: 582, Loss: 1009.5751953125,State: [2745  300 2165 2766  525]\n",
            "Episode: 584, Loss: 1200.9261474609375,State: [2745 1453  533 1244  287]\n",
            "Episode: 586, Loss: 670.9514770507812,State: [1109 2745 1337 2742 1133]\n",
            "Episode: 588, Loss: 23400.244140625,State: [1367 2745 2327 2894 1099]\n",
            "Episode: 590, Loss: 4826.7998046875,State: [2745  714  403 2624  158]\n",
            "Episode: 592, Loss: 582.0014038085938,State: [2745 2488  103 2574  451]\n",
            "Episode: 594, Loss: 2581.694580078125,State: [2745 2323 2266 2235   83]\n",
            "Episode: 596, Loss: 1026.3138427734375,State: [2745 2428 1500  322 1532]\n",
            "Episode: 598, Loss: 418.1963806152344,State: [2745  305 2376 2653 2500]\n",
            "Episode: 600, Loss: 13244.330078125,State: [2745 1553 2888 1663 2025]\n",
            "Episode: 602, Loss: 164.61203002929688,State: [2745  876  328 1558  301]\n",
            "Episode: 604, Loss: 16184.8125,State: [ 860 2745 1177  176 2436]\n",
            "Episode: 606, Loss: 15487.900390625,State: [2745  732 1034 1845 1571]\n",
            "Episode: 608, Loss: 3881.63916015625,State: [2745 1534 2738  812 1927]\n",
            "Episode: 610, Loss: 424.2844543457031,State: [2745  803  249  476 2293]\n",
            "Episode: 612, Loss: 1850.4718017578125,State: [2745 2333  806 2407  727]\n",
            "Episode: 614, Loss: 1008.8796997070312,State: [2745  925 2250 1907  981]\n",
            "Episode: 616, Loss: 2767.968505859375,State: [2745 1154 2244 2741 1339]\n",
            "Episode: 618, Loss: 1467.22900390625,State: [2745  906 1193  708 2611]\n",
            "Episode: 620, Loss: 315.9943542480469,State: [1184 2745 1983    5 2307]\n",
            "Episode: 622, Loss: 3721.97607421875,State: [2745 1352 2660 2131 1101]\n",
            "Episode: 624, Loss: 14.315056800842285,State: [2745  692 2313  719 2609]\n",
            "Episode: 626, Loss: 14271.1455078125,State: [2745 1066  259 1616 2300]\n",
            "Episode: 628, Loss: 655.288330078125,State: [2745   96  545 2174  107]\n",
            "Episode: 630, Loss: 3916.337646484375,State: [1930 1208 2745 2693  397]\n",
            "Episode: 632, Loss: 924.2732543945312,State: [2745 1981 2317 2839 1853]\n",
            "Episode: 634, Loss: 188.49705505371094,State: [2745  996 1908 1954  252]\n",
            "Episode: 636, Loss: 69.44337463378906,State: [2745   73 1119 2715 1637]\n",
            "Episode: 638, Loss: 1881.8292236328125,State: [2745 1852  355  432 2645]\n",
            "Episode: 640, Loss: 31043.123046875,State: [2745 2822  905 1013 2395]\n",
            "Episode: 642, Loss: 11827.4638671875,State: [2745 2166  947  929 2836]\n",
            "Episode: 644, Loss: 1707.1666259765625,State: [2745   84  698  621  681]\n",
            "Episode: 646, Loss: 6677.05419921875,State: [2745 1259  425 1726 2206]\n",
            "Episode: 648, Loss: 5760.2763671875,State: [2745 2424  337 1577 2381]\n",
            "Episode: 650, Loss: 446.07525634765625,State: [2745  549 2654 2065 1633]\n",
            "Episode: 652, Loss: 164.95628356933594,State: [2745 1142  840 2501  537]\n",
            "Episode: 654, Loss: 398.1275329589844,State: [2745 2340    7  332 2304]\n",
            "Episode: 656, Loss: 16933.103515625,State: [2745  399 1248 2201 1363]\n",
            "Episode: 658, Loss: 990.4677734375,State: [2745 1117  280  527 2741]\n",
            "Episode: 660, Loss: 2580.476806640625,State: [2745  983 2463 2702 1052]\n",
            "Episode: 662, Loss: 17852.189453125,State: [2745   79  973 1538 2422]\n",
            "Episode: 664, Loss: 13558.5986328125,State: [2745 1235 2818 1556  974]\n",
            "Episode: 666, Loss: 7300.96484375,State: [2745 2420 1572  355 2438]\n",
            "Episode: 668, Loss: 2840.56884765625,State: [2425 2745 1763 2154  286]\n",
            "Episode: 670, Loss: 6978.3193359375,State: [2745 1179 1567 1100 2262]\n",
            "Episode: 672, Loss: 1473.954833984375,State: [2745 2742 1843 1405 1240]\n",
            "Episode: 674, Loss: 6510.6298828125,State: [2745 1552  528  857 2069]\n",
            "Episode: 676, Loss: 258.26324462890625,State: [1079 2745  791 2594 2509]\n",
            "Episode: 678, Loss: 282.6114196777344,State: [2745 1923 1660 2861 2843]\n",
            "Episode: 680, Loss: 14169.6513671875,State: [1198  748 2745 2283   84]\n",
            "Episode: 682, Loss: 15189.8291015625,State: [2745 1684  511 2162  800]\n",
            "Episode: 684, Loss: 1269.39306640625,State: [2745 1322 2297 2775 2464]\n",
            "Episode: 686, Loss: 26807.345703125,State: [2745 1395 2175  630  678]\n",
            "Episode: 688, Loss: 11265.251953125,State: [2745 1086  876 2071   65]\n",
            "Episode: 690, Loss: 9317.0751953125,State: [2745 2354 2671 1415 1098]\n",
            "Episode: 692, Loss: 1861.6318359375,State: [2745 2634 2815  777 2389]\n",
            "Episode: 694, Loss: 1531.505126953125,State: [2745  436 1967   92  577]\n",
            "Episode: 696, Loss: 1084.4267578125,State: [2745 2595    6 1062 1972]\n",
            "Episode: 698, Loss: 1212.421630859375,State: [2745 1315 2679 1132 1792]\n",
            "Episode: 700, Loss: 229.54122924804688,State: [2745 1728 1732 1960 2917]\n",
            "Episode: 702, Loss: 2788.455078125,State: [2745 2508  877  991 2264]\n",
            "Episode: 704, Loss: 9797.4658203125,State: [2745 1601   57 1758 1732]\n",
            "Episode: 706, Loss: 7783.8818359375,State: [2745 2624 1940 2493  562]\n",
            "Episode: 708, Loss: 9988.869140625,State: [2745 1565 1958 2881 1686]\n",
            "Episode: 710, Loss: 2829.845703125,State: [2745  227  683 2629 2124]\n",
            "Episode: 712, Loss: 1723.3336181640625,State: [2745  661  659 1296 2120]\n",
            "Episode: 714, Loss: 395.56622314453125,State: [2745 2706  911 1987  886]\n",
            "Episode: 716, Loss: 40241.2890625,State: [2745 1370 2261 1242  559]\n",
            "Episode: 718, Loss: 6341.93017578125,State: [2745  137 1316  761 1986]\n",
            "Episode: 720, Loss: 5066.83056640625,State: [2745 2636 2284   64 2551]\n",
            "Episode: 722, Loss: 657.848876953125,State: [2745  575 1162  386  210]\n",
            "Episode: 724, Loss: 6542.75439453125,State: [2745  580 1122 2417  797]\n",
            "Episode: 726, Loss: 410.0003967285156,State: [2745 2381 1857 1552 1352]\n",
            "Episode: 728, Loss: 26428.080078125,State: [2745 2882 1214  147 2384]\n",
            "Episode: 730, Loss: 10293.7890625,State: [2745   49 1982 2699 1410]\n",
            "Episode: 732, Loss: 198.38282775878906,State: [2745 1423 2539  734 2457]\n",
            "Episode: 734, Loss: 2247.736328125,State: [2745 1354  189 2715 2819]\n",
            "Episode: 736, Loss: 5165.81298828125,State: [2745 1621 2367 2590  635]\n",
            "Episode: 738, Loss: 738.5300903320312,State: [2745 2902 2668 2279 2244]\n",
            "Episode: 740, Loss: 690.0603637695312,State: [2745 2658  685   51 2867]\n",
            "Episode: 742, Loss: 339.0338134765625,State: [2745 2593 1170 2407 1694]\n",
            "Episode: 744, Loss: 1589.262939453125,State: [2745 2558  679 2589 1552]\n",
            "Episode: 746, Loss: 915.9501953125,State: [2745 2719 2897 1122  740]\n",
            "Episode: 748, Loss: 2517.384765625,State: [1419 2745 1222 1479 2707]\n",
            "Episode: 750, Loss: 1483.8624267578125,State: [2745 2456 1758 1467 2769]\n",
            "Episode: 752, Loss: 1296.241455078125,State: [1079 2745 1029 2129 1415]\n",
            "Episode: 754, Loss: 2063.936767578125,State: [2745  117  536 1403  666]\n",
            "Episode: 756, Loss: 1594.75,State: [2745 2187 1213  683 1916]\n",
            "Episode: 758, Loss: 721.0786743164062,State: [1934 2745 2000  382  792]\n",
            "Episode: 760, Loss: 610.8522338867188,State: [2745 1604  451 2844 2901]\n",
            "Episode: 762, Loss: 166.61419677734375,State: [1763 2745 2614 1488  773]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.read_csv(\"new_data.csv\")"
      ],
      "metadata": {
        "id": "jhR2BSxHKJ0R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test the trained agent\n",
        "def test_agent(env, model, num_episodes=3, max_steps=300):\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()  # Reset the environment\n",
        "        total_reward = 0  # Initialize total reward for the episode\n",
        "        print(f\"Testing Episode {episode + 1}:\")\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            state_tensor = tf.expand_dims(tf.convert_to_tensor(state), 0)  # Convert to tensor\n",
        "            logits, _ = model(state_tensor)  # Get action logits\n",
        "\n",
        "            # Sample action from the policy distribution\n",
        "            action = tf.random.categorical(logits, 1)[0, 0].numpy()  # Sample an action\n",
        "            next_state, reward, done, _ = env.step(action)  # Take action in the environment\n",
        "\n",
        "            total_reward += reward  # Accumulate reward\n",
        "            state = next_state  # Update state\n",
        "\n",
        "            # Optional: Render the environment (if your env supports it)\n",
        "            # env.render()\n",
        "\n",
        "            if done:\n",
        "                break  # End episode if done\n",
        "\n",
        "        print(f\"Total Reward for Episode {episode + 1}:{reward}, {final_df.iloc[env.state]}\")\n",
        "\n",
        "# Testing the agent\n",
        "test_agent(env, model, num_episodes=1)  # Test the agent for 10 episodes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUVaNUqyJlBZ",
        "outputId": "70d9b5e7-101d-441d-fca3-24ad33f8764f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Episode 1:\n",
            "Total Reward for Episode 1:0,       Unnamed: 0  S.no                              Title  \\\n",
            "2745        2745  2745               PVC Shoulder Stretch   \n",
            "56            56    56  HM Alternating Dumbbell Plank Row   \n",
            "562          562   562           Holman Side Plank Crunch   \n",
            "926          926   926                     Band chest fly   \n",
            "87            87    87                 Lying Leg Pullover   \n",
            "\n",
            "                                                   Desc        Type  \\\n",
            "2745                                                NaN  Stretching   \n",
            "56                                                  NaN    Strength   \n",
            "562                                                 NaN    Strength   \n",
            "926   Similar to the cable chest fly, the band chest...    Strength   \n",
            "87                                                  NaN    Strength   \n",
            "\n",
            "        BodyPart  Equipment         Level  \n",
            "2745   Shoulders  Body Only  Intermediate  \n",
            "56    Abdominals   Dumbbell  Intermediate  \n",
            "562   Abdominals  Body Only  Intermediate  \n",
            "926        Chest      Bands  Intermediate  \n",
            "87    Abdominals   Dumbbell  Intermediate  \n"
          ]
        }
      ]
    }
  ]
}